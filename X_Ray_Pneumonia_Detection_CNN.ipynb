{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from keras.layers import Dense, InputLayer,Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18507ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the category of classification\n",
    "Categories = [\"NORMAL\", \"PNEUMONIA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f9d71",
   "metadata": {},
   "source": [
    "## Preparing Trainig Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir_Tranining = \"chest_xray/train\"\n",
    "\n",
    "# Converting the image to Grayscale\n",
    "for category in Categories:\n",
    "    path = os.path.join(DataDir_Tranining, category)\n",
    "    for img in os.listdir(path):\n",
    "        imgs = os.path.join(path, img)\n",
    "        img_array = cv2.imread(imgs, cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 100 # Initializing the size of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image after resizing and grayscale conversion\n",
    "new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "plt.imshow(new_array, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "# Defining function for training data according to the categories converting the images into gray scale with resolution\n",
    "# Converting the images into array\n",
    "\n",
    "def create_train_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(DataDir_Tranining, category)\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "create_train_data()\n",
    "print(len(training_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1408074",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16810e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Splitting the features and labels\n",
    "for features, label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed043016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386c93d",
   "metadata": {},
   "source": [
    "## Preparing Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We doing doing same with training data\n",
    "validation_data = []\n",
    "DataDir_Validation = \"chest_xray/validation\"\n",
    "\n",
    "def create_validation_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(DataDir_Validation, category)\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                validation_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_validation_data()\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ae887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for features, label in validation_data:\n",
    "    X_val.append(features)\n",
    "    y_val.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val = np.array(X_val).reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64852061",
   "metadata": {},
   "source": [
    "## Preparing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0522160",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "DataDir_Testing = \"chest_xray/test\"\n",
    "def create_test_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(DataDir_Testing, category)\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                testing_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_test_data()\n",
    "print(len(testing_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cc6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7254bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test).reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6eef9",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8524d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "X_test = X_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Pneumnia_Classifier(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [2, 4, 16, 32, 64]\n",
    "EPOCHS_LIST = [10, 20, 30]\n",
    "\n",
    "results = []\n",
    "best_acc = -1\n",
    "best_training_acc = -1\n",
    "best_validation_acc = -1\n",
    "best_info = None\n",
    "input_size =X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in EPOCHS_LIST:\n",
    "    for bs in BATCH_SIZES:\n",
    "        print(f\"Starting run: batch_size={bs}, epochs={ep}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        m = Pneumnia_Classifier(input_size)\n",
    "        history = m.fit(X_train, y_train, batch_size=bs,epochs=ep, validation_data=(X_val, y_val), verbose=1)\n",
    "        acc_mean = round(np.mean(history.history['accuracy']) * 100, 2)\n",
    "        acc_val_mean = round(np.mean(history.history['val_accuracy']) * 100, 2)\n",
    "        score = m.evaluate(X_test, y_test, verbose=0)\n",
    "        curr_acc = round(score[1] * 100, 2)\n",
    "        results.append((bs, ep, acc_mean, acc_val_mean, curr_acc))\n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_training_acc = acc_mean\n",
    "            best_validation_acc = acc_val_mean\n",
    "            best_info = f'Batch_Size : {bs}, Epochs : {ep}, Training_Accuracy : {best_training_acc}, Validation_Accuracy : {best_validation_acc}, Test_Accuracy : {best_acc}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Result -> \", best_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6171c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['Batch_Size', 'Epochs', 'Training_Accuracy', 'Validation_Accuracy', 'Test_Accuracy'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'Model/Pneumonia_Detection_CNN_{round(best_acc, 0)}.keras'\n",
    "tf.keras.models.save_model(m, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
